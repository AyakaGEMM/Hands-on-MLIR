#include "HOM/HOMOps.td"
#include "HOMNVGPU/HOMNVGPUOps.td"

Pattern {
  let root = op<hom.matmul_add>(input0 : Value, input1 : Value, input2 : Value);

  replace root with op<homnvgpu.matmul>(input0, input1, input2){
      alpha = attr<"1.0 : f32">, beta = attr<"1.0 : f32">,
      act = attr<"0 : i32">};
}

Pattern {
  let root = op<hom.matmul>(input0
                            : Value, input1
                            : Value)
                 ->(resultType
                    : Type);

  rewrite root with {
    let dummy_tensor = op<hom.dummy_tensor>->(resultType);
    replace root with op<homnvgpu.matmul>(input0, input1, dummy_tensor){
        alpha = attr<"1.0 : f32">, beta = attr<"0.0 : f32">,
        act = attr<"0 : i32">};
  };
}

Pattern {
  let act = attr<"0 : i32">;
  let matmul = op<homnvgpu.matmul>(
      input0
      : Value, input1
      : Value, input2
      : Value){act = act, alpha = A : Attr, beta = B : Attr};
  let root = op<hom.gelu>(matmul);

  rewrite root with {
    replace root with op<homnvgpu.matmul>(input0, input1, input2){
        act = attr<"1 : i32">, alpha = A, beta = B};
    erase matmul;
  };
}

Pattern {
  let root = op<hom.layernorm>(input
                               : Value){axis = axis : Attr, eps = eps : Attr};

  replace root with op<homnvgpu.layernorm>(input){axis = axis, eps = eps};
}

Pattern {
  let root = op<hom.bert_mha>(
      qkv
      : Value, mask
      : Value){scale = scale : Attr, head_num = head_num : Attr};

  replace root with op<homnvgpu.bert_mha>(qkv, mask){scale = scale,
                                                     head_num = head_num};
}

Pattern {
  let root = op<hom.add>(a : Value, b : Value);

  replace root with op<homnvgpu.add>(a, b);
}

Pattern {
  let root = op<hom.gather>(a : Value, b : Value);

  replace root with op<homnvgpu.gather>(a, b);
}
