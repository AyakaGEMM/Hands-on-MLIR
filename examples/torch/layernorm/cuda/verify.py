import torch

a = """
0.840332 0.394287 0.783203 0.79834 0.911621 0.19751 0.335205 0.768066 0.277832 0.554199 0.477295 0.628906 0.364746 0.513184 0.952148 0.916016 0.635742 0.717285 0.141602 0.606934 0.0162964 0.24292 0.137207 0.804199 0.156738 0.400879 0.129761 0.108826 0.999023 0.218262 0.512695 0.839355
0.612793 0.296143 0.637695 0.524414 0.493652 0.972656 0.29248 0.771484 0.526855 0.77002 0.400146 0.891602 0.283203 0.352539 0.807617 0.918945 0.0697632 0.949219 0.525879 0.0860596 0.192261 0.663086 0.890137 0.348877 0.0641479 0.0200195 0.457764 0.0631104 0.238281 0.970703 0.902344 0.851074

0.266602 0.539551 0.375244 0.760254 0.512695 0.66748 0.531738 0.0392761 0.437744 0.931641 0.930664 0.721191 0.28418 0.73877 0.640137 0.354004 0.687988 0.166016 0.440186 0.879883 0.829102 0.330322 0.229004 0.893555 0.350342 0.686523 0.956543 0.588867 0.657227 0.858887 0.439453 0.923828
0.398438 0.814941 0.684082 0.911133 0.482422 0.21582 0.950195 0.919922 0.147705 0.880859 0.641113 0.431885 0.619629 0.281006 0.786133 0.307373 0.447021 0.226074 0.1875 0.276123 0.556641 0.416504 0.169556 0.906738 0.103149 0.126099 0.495361 0.760254 0.984863 0.935059 0.68457 0.383301
"""

b = """
0.75 0.368652 0.294189 0.2323 0.584473 0.244385 0.152344 0.731934
0.125488 0.793457 0.164062 0.745117 0.0745239 0.950195 0.0525208 0.521484
0.17627 0.240112 0.797852 0.732422 0.656738 0.967285 0.639648 0.759766
0.0935059 0.134888 0.52002 0.0782471 0.0698853 0.204712 0.461426 0.819824
0.573242 0.755371 0.0519409 0.157837 1 0.204346 0.890137 0.125488
0.997559 0.0540466 0.870605 0.0723267 0.00416183 0.922852 0.59375 0.18042
0.163086 0.391602 0.913086 0.819824 0.359131 0.552246 0.57959 0.452637
0.6875 0.0996704 0.530762 0.757324 0.304199 0.992188 0.577148 0.877441
0.748047 0.628906 0.0354309 0.748047 0.833008 0.925293 0.873047 0.831055
0.979492 0.743652 0.90332 0.983398 0.666992 0.497314 0.16394 0.830078
0.88916 0.0769653 0.649902 0.248047 0.629395 0.229126 0.700684 0.316895
0.328857 0.231445 0.0741577 0.633301 0.223633 0.651367 0.510742 0.97168
0.280029 0.545898 0.719238 0.113281 0.471436 0.592773 0.944336 0.450928
0.336426 0.847656 0.43457 0.00323105 0.344971 0.598633 0.833008 0.233887
0.675293 0.48291 0.481934 0.304932 0.711914 0.182495 0.621582 0.040863
0.414062 0.695801 0.673828 0.637695 0.347168 0.18457 0.608887 0.626953
0.730957 0.328369 0.740234 0.202271 0.920898 0.68457 0.65332 0.257324
0.532227 0.0876465 0.260498 0.877441 0.686035 0.09375 0.111267 0.361572
0.57666 0.593262 0.666504 0.288818 0.775879 0.28833 0.32959 0.189697
0.984375 0.00357819 0.827148 0.331543 0.188232 0.436523 0.958496 0.918945
0.764648 0.699219 0.121155 0.685547 0.383789 0.774414 0.942871 0.916504
0.861816 0.203491 0.793457 0.547852 0.297363 0.904785 0.909668 0.874023
0.498047 0.576172 0.16272 0.273926 0.864746 0.492432 0.463623 0.849121
0.496094 0.291016 0.18042 0.684082 0.727539 0.139038 0.603027 0.492432
0.837891 0.724121 0.178223 0.221924 0.498535 0.121277 0.138184 0.360352
0.324707 0.932129 0.908691 0.62207 0.836914 0.818359 0.496094 0.334961
0.394287 0.658691 0.608887 0.258789 0.151245 0.0725708 0.107849 0.646973
0.363525 0.28833 0.331299 0.0911255 0.427246 0.93457 0.583496 0.265381
0.658691 0.761719 0.487549 0.157227 0.882812 0.625488 0.517578 0.207886
0.557617 0.42627 0.830078 0.394287 0.244385 0.325928 0.729492 0.638672
0.984863 0.338135 0.897461 0.136108 0.410889 0.00540924 0.783203 0.774414
0.293701 0.114685 0.865723 0.721191 0.0491638 0.449219 0.986328 0.708008
"""

c = """
0.210938 0.473877 0.865234 0.0939331 0.0995483 0.382812 0.301758 0.657227 0.809082 0.131714 0.0515137 0.0534363 0.457764 0.780762 0.691895 0.442627
0.119141 0.589844 0.578613 0.529785 0.595215 0.361816 0.304199 0.888672 0.476562 0.1698 0.609863 0.525879 0.619141 0.596191 0.233643 0.82959
0.0700684 0.0988159 0.923828 0.169678 0.481689 0.225464 0.82666 0.290771 0.357178 0.878418 0.344238 0.814941 0.65918 0.0363159 0.257568 0.77832
0.625977 0.835938 0.308105 0.221069 0.197998 0.612305 0.109741 0.674805 0.782227 0.719238 0.200317 0.401123 0.315674 0.434082 0.230957 0.385742
0.532715 0.154663 0.555176 0.0145798 0.380127 0.38208 0.30542 0.737305 0.260498 0.649902 0.552246 0.919434 0.686035 0.80957 0.697754 0.312012
0.645996 0.00600433 0.533203 0.84375 0.618652 0.642578 0.518555 0.400635 0.362061 0.71875 0.801758 0.677734 0.152832 0.0328979 0.0635376 0.685547
0.187622 0.619141 0.700195 0.567871 0.00112534 0.0057106 0.305176 0.261475 0.655273 0.857422 0.181152 0.341309 0.66748 0.878906 0.65332 0.313232
0.885254 0.186279 0.157104 0.503418 0.829102 0.675781 0.904297 0.191162 0.394531 0.706055 0.869141 0.547363 0.73877 0.932617 0.233154 0.926758
"""


def parse(x):
    x = [
        [float(j) for j in i.strip().split()]
        for i in x.strip().split("\n")
        if i.strip() != ""
    ]
    print(x)
    return torch.tensor(x)


a_tensor = parse(a)
b_tensor = parse(b)
c_tensor = parse(c)

ab = a_tensor @ b_tensor

print(ab)

mean = ab.mean(-1)
square_mean = (ab * ab).mean(-1)

var = 1 / torch.sqrt(square_mean - mean * mean + 1e-5)
new_mean = -mean * var

print(var)
print(new_mean)

print(ab.shape, mean.unsqueeze(1).shape)

new_ab = (ab - mean.unsqueeze(-1)) * var.unsqueeze(-1)

ln = torch.nn.LayerNorm((ab.shape[1],), bias=False, eps=1e-6)

print(ln(ab) @ c_tensor)
